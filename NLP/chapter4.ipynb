{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "#### 패키지 설치"
      ],
      "metadata": {
        "id": "RDuFUQkYqVXS"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "id": "T91V8yhEqUiR"
      },
      "outputs": [],
      "source": [
        "!pip install ratsnlp -q"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/gdrive', force_remount = True)\n",
        "# 구글 드라이브 설정"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BWKxwrtwqaj0",
        "outputId": "abe89ec0-5dc4-499a-952f-3c4c4c7ac1fa"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /gdrive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 모델 환경설정\n",
        "- 하이퍼파라미터와 저장 위치 등 설정 정보 선언"
      ],
      "metadata": {
        "id": "vM4DVsPiqmVe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from ratsnlp.nlpbook.classification import ClassificationTrainArguments\n",
        "\n",
        "args = ClassificationTrainArguments(\n",
        "    pretrained_model_name= \"beomi/kcbert-base\",# 프리트레인 마친 언어 모델의 이름\n",
        "    downstream_corpus_name=\"nsmc\", # 다운스트림 데이터의 이름\n",
        "    downstream_model_dir=\"/gdrive/My Drive/nlpbook/checkpoint-doccls\",# 파인튜닝된 모델의 체크포인트가 저장될 위치.\n",
        "    batch_size = 32 if torch.cuda.is_available() else 4,\n",
        "    learning_rate = 5e-5,\n",
        "    max_seq_length = 128,\n",
        "    epochs = 3,\n",
        "    tpu_cores = 0 if torch.cuda.is_available() else 8,\n",
        "    seed = 7\n",
        ")"
      ],
      "metadata": {
        "id": "y54CI2Izqi6D"
      },
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 랜덤시드 고정\n",
        "- 학습 재현을 위해 랜덤 시드를 고정합니다.\n"
      ],
      "metadata": {
        "id": "4s5wsiiBrODk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from ratsnlp import nlpbook\n",
        "\n",
        "nlpbook.set_seed(args)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HBnFKwU6qp4W",
        "outputId": "cd012c84-4889-4dfa-b6a8-f708d6242d37"
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "set seed: 7\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 로거 설정 \n",
        "- 메세지 출력 등을 위한 logger를 설정합니다."
      ],
      "metadata": {
        "id": "sD03R_QHJWCp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "nlpbook.set_logger(args) "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "woV6vXQNrQGI",
        "outputId": "edc74244-c2e4-44de-918b-a7a5f63b3b7c"
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:ratsnlp:Training/evaluation parameters ClassificationTrainArguments(pretrained_model_name='beomi/kcbert-base', downstream_task_name='document-classification', downstream_corpus_name='nsmc', downstream_corpus_root_dir='/content/Korpora', downstream_model_dir='/gdrive/My Drive/nlpbook/checkpoint-doccls', max_seq_length=128, save_top_k=1, monitor='min val_loss', seed=7, overwrite_cache=False, force_download=False, test_mode=False, learning_rate=5e-05, epochs=3, batch_size=4, cpu_workers=2, fp16=False, tpu_cores=8)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 말뭉치 내려받기"
      ],
      "metadata": {
        "id": "FtEKTSwkrVvE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from Korpora import Korpora\n",
        "\n",
        "Korpora.fetch(\n",
        "    corpus_name = args.downstream_corpus_name,\n",
        "    root_dir = args.downstream_corpus_root_dir,\n",
        "    force_download=True,\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JRzNOO89rUYZ",
        "outputId": "e1ade165-a98e-4938-80a4-90c7a2369194"
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nsmc] download ratings_train.txt: 14.6MB [00:00, 63.2MB/s]                            \n",
            "[nsmc] download ratings_test.txt: 4.90MB [00:00, 33.2MB/s]                           \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 토크나이저 준비하기"
      ],
      "metadata": {
        "id": "GpXnD1_fraCv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import BertTokenizer\n",
        "\n",
        "tokenizer = BertTokenizer.from_pretrained(\n",
        "    args.pretrained_model_name,\n",
        "    do_lower_case = False\n",
        ")"
      ],
      "metadata": {
        "id": "Klecc46lrZgO"
      },
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 데이터 전처리하기"
      ],
      "metadata": {
        "id": "g9AI1St0reBo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from ratsnlp.nlpbook.classification import NsmcCorpus, ClassificationDataset\n",
        "\n",
        "corpus = NsmcCorpus()\n",
        "train_dataset = ClassificationDataset(\n",
        "    args = args,\n",
        "    corpus = corpus,\n",
        "    tokenizer = tokenizer,\n",
        "    mode = \"train\"\n",
        ")"
      ],
      "metadata": {
        "id": "h9k3tHCdKlQx",
        "outputId": "a01fd279-f34d-4552-877d-63d1e23f3a21",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:ratsnlp:Loading features from cached file /content/Korpora/nsmc/cached_train_BertTokenizer_128_nsmc_document-classification [took 23.259 s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "- ClassificationDataset : NsmcCorpus와 토크나이저를 품고 있습니다.\n",
        "   - NsmcCorpus가 넘겨준 문장과 레이블 각각 토크나이저를 활용해 모델 학습할 수 있는 형태로 가공\n",
        "- NsmcCorpus 는 csv파일 형식의 NSCM의 데이터를 문장과 레이블로 읽어 들입니다."
      ],
      "metadata": {
        "id": "pYvhLCJarlUA"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- Classification Features 자료형\n",
        "   - input_ids : 인덱스로 변환된 토큰 시퀀스\n",
        "   - attention_mask : 해당토큰이 패딩토큰(0)인지 아닌지(1) 나타냄\n",
        "   - token_type_ids : 세그먼트 정보\n",
        "   - label : 정수로 바뀐 레이블 정보"
      ],
      "metadata": {
        "id": "XnVsJe4rrl3m"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 학습데이터 로더"
      ],
      "metadata": {
        "id": "Rf5LNjy6M2kt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.utils.data import DataLoader, RandomSampler\n",
        "\n",
        "train_dataloader = DataLoader(\n",
        "    train_dataset,\n",
        "    batch_size = args.batch_size,\n",
        "    sampler = RandomSampler(train_dataset, replacement = False),\n",
        "    collate_fn = nlpbook.data_collator,\n",
        "    drop_last = False,\n",
        "    num_workers = args.cpu_workers\n",
        ")"
      ],
      "metadata": {
        "id": "860cLl8SMx-l"
      },
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "- sampler : 샘플링 방식을 정의합니다.\n",
        "- collate_fn : 배치 사이즈 만큼 비복원 랜덤 추출한 인스턴스들을 배치로 만드는 역할\n"
      ],
      "metadata": {
        "id": "AXtr5wOyr5LW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_dataset[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XVqP1KtTrha3",
        "outputId": "37bb4ca1-5302-4088-a78f-a554cdf89990"
      },
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "ClassificationFeatures(input_ids=[2, 2170, 832, 5045, 17, 17, 7992, 29734, 4040, 10720, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], attention_mask=[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], token_type_ids=[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], label=0)"
            ]
          },
          "metadata": {},
          "execution_count": 45
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 평가용 데이터 로더 구축"
      ],
      "metadata": {
        "id": "LvneZIiAr7XP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.utils.data import SequentialSampler\n",
        "\n",
        "val_dataset = ClassificationDataset(\n",
        "    args = args,\n",
        "    corpus = corpus,\n",
        "    tokenizer = tokenizer,\n",
        "    mode = \"test\"\n",
        ")\n",
        "val_dataloader = DataLoader(\n",
        "    val_dataset,\n",
        "    batch_size=args.batch_size,\n",
        "    sampler=SequentialSampler(val_dataset),\n",
        "    collate_fn=nlpbook.data_collator,\n",
        "    drop_last=False,\n",
        "    num_workers=args.cpu_workers,\n",
        ")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xfulNX4Hr6PX",
        "outputId": "fbd6934e-0ba9-4353-a53e-c7490fe4efa1"
      },
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:ratsnlp:Loading features from cached file /content/Korpora/nsmc/cached_test_BertTokenizer_128_nsmc_document-classification [took 8.239 s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 모델 초기화"
      ],
      "metadata": {
        "id": "BrW-DOAesFNP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import BertConfig, BertForSequenceClassification\n",
        "\n",
        "pretrained_model_config = BertConfig.from_pretrained(\n",
        "    args.pretrained_model_name,\n",
        "    num_labels = corpus.num_labels\n",
        ")\n",
        "\n",
        "model = BertForSequenceClassification.from_pretrained(\n",
        "    args.pretrained_model_name,\n",
        "    config = pretrained_model_config\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AmTbkNH_sBi1",
        "outputId": "7393b7c6-dd9e-4d0c-a917-15e8bd318b66"
      },
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of the model checkpoint at beomi/kcbert-base were not used when initializing BertForSequenceClassification: ['cls.seq_relationship.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.seq_relationship.weight', 'cls.predictions.bias', 'cls.predictions.decoder.bias']\n",
            "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at beomi/kcbert-base and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### task 정의\n"
      ],
      "metadata": {
        "id": "wK-CisAisPbq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from ratsnlp.nlpbook.classification import ClassificationTask\n",
        "task = ClassificationTask(model, args)"
      ],
      "metadata": {
        "id": "-CJvRTIxsNve"
      },
      "execution_count": 48,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "- 옵티마이저 : 아담 Adam\n",
        "- 러닝 레이트 스케줄러 : ExponentialLR\n",
        "   - 현재 에포크의 러닝 레이트 : 이전 에포크의 러닝 레이트 X gamma(0.9)"
      ],
      "metadata": {
        "id": "nFquF6amscrK"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 학습"
      ],
      "metadata": {
        "id": "avTtjFp4sgjz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "trainer = nlpbook.get_trainer(args)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 360
        },
        "id": "--YNFpLNOaK4",
        "outputId": "aeb5c1d9-be8b-44d6-d789-b753fc53f723"
      },
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "error",
          "ename": "MisconfigurationException",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mMisconfigurationException\u001b[0m                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-49-7c6e0a07330b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtrainer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnlpbook\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_trainer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/ratsnlp/nlpbook/trainer.py\u001b[0m in \u001b[0;36mget_trainer\u001b[0;34m(args, return_trainer_only)\u001b[0m\n\u001b[1;32m     26\u001b[0m         \u001b[0mprecision\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m16\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfp16\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;36m32\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m         \u001b[0;31m# For TPU Setup\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 28\u001b[0;31m         \u001b[0mtpu_cores\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtpu_cores\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtpu_cores\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     29\u001b[0m     )\n\u001b[1;32m     30\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mreturn_trainer_only\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pytorch_lightning/utilities/argparse.py\u001b[0m in \u001b[0;36minsert_env_defaults\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    337\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    338\u001b[0m         \u001b[0;31m# all args were already moved to kwargs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 339\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    340\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    341\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mcast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_T\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minsert_env_defaults\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pytorch_lightning/trainer/trainer.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, logger, checkpoint_callback, enable_checkpointing, callbacks, default_root_dir, gradient_clip_val, gradient_clip_algorithm, process_position, num_nodes, num_processes, devices, gpus, auto_select_gpus, tpu_cores, ipus, log_gpu_memory, progress_bar_refresh_rate, enable_progress_bar, overfit_batches, track_grad_norm, check_val_every_n_epoch, fast_dev_run, accumulate_grad_batches, max_epochs, min_epochs, max_steps, min_steps, max_time, limit_train_batches, limit_val_batches, limit_test_batches, limit_predict_batches, val_check_interval, flush_logs_every_n_steps, log_every_n_steps, accelerator, strategy, sync_batchnorm, precision, enable_model_summary, weights_summary, weights_save_path, num_sanity_val_steps, resume_from_checkpoint, profiler, benchmark, deterministic, reload_dataloaders_every_n_epochs, auto_lr_find, replace_sampler_ddp, detect_anomaly, auto_scale_batch_size, prepare_data_per_node, plugins, amp_backend, amp_level, move_metrics_to_cpu, multiple_trainloader_mode, stochastic_weight_avg, terminate_on_nan)\u001b[0m\n\u001b[1;32m    498\u001b[0m             \u001b[0mamp_type\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mamp_backend\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    499\u001b[0m             \u001b[0mamp_level\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mamp_level\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 500\u001b[0;31m             \u001b[0mplugins\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mplugins\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    501\u001b[0m         )\n\u001b[1;32m    502\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_logger_connector\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mLoggerConnector\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlog_gpu_memory\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pytorch_lightning/trainer/connectors/accelerator_connector.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, devices, num_nodes, accelerator, strategy, plugins, precision, amp_type, amp_level, sync_batchnorm, benchmark, replace_sampler_ddp, deterministic, auto_select_gpus, num_processes, tpu_cores, ipus, gpus)\u001b[0m\n\u001b[1;32m    194\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_accelerator_flag\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"auto\"\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_accelerator_flag\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    195\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_accelerator_flag\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_choose_accelerator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 196\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_set_parallel_devices_and_init_accelerator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    197\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    198\u001b[0m         \u001b[0;31m# 3. Instantiate ClusterEnvironment\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pytorch_lightning/trainer/connectors/accelerator_connector.py\u001b[0m in \u001b[0;36m_set_parallel_devices_and_init_accelerator\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    513\u001b[0m             ]\n\u001b[1;32m    514\u001b[0m             raise MisconfigurationException(\n\u001b[0;32m--> 515\u001b[0;31m                 \u001b[0;34mf\"{self.accelerator.__class__.__qualname__} can not run on your system\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    516\u001b[0m                 \u001b[0;34m\" since the accelerator is not available. The following accelerator(s)\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    517\u001b[0m                 \u001b[0;34m\" is available and can be passed into `accelerator` argument of\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mMisconfigurationException\u001b[0m: TPUAccelerator can not run on your system since the accelerator is not available. The following accelerator(s) is available and can be passed into `accelerator` argument of `Trainer`: ['cpu']."
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "trainer.fit(\n",
        "    task,\n",
        "    train_dataloaders = train_dataloader,\n",
        "    val_dataloaders = val_dataloader)"
      ],
      "metadata": {
        "id": "5T1ghtUcsfQr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 실전 투입\n"
      ],
      "metadata": {
        "id": "NaBJZio3snjZ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 각종 설정\n",
        "- 모델 하이퍼파라메터(hyperparameter)와 저장 위치 등 설정 정보를 선언합니다."
      ],
      "metadata": {
        "id": "u2goRxRlQw6m"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from ratsnlp.nlpbook.classification import ClassificationDeployArguments\n",
        "\n",
        "args = ClassificationDeployArguments(\n",
        "    pretrained_model_name = \"beomi/kcbert-base\",\n",
        "    downstream_model_dir=\"/gdrive/MyDrive/nlpbook/checkpoint-doccls\",\n",
        "    max_seq_length = 128\n",
        ")"
      ],
      "metadata": {
        "id": "RplyNmk3Q_nR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 토크나이저 로드"
      ],
      "metadata": {
        "id": "C3dtM-GbRLy4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import BertTokenizer\n",
        "\n",
        "tokenizer = BertTokenizer.from_pretrained(\n",
        "    args.pretrained_model_name,\n",
        "    do_lower_case = False\n",
        ")"
      ],
      "metadata": {
        "id": "9eS2d331tHK-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 체크포인트 로드"
      ],
      "metadata": {
        "id": "yz32mVvKROAo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "\n",
        "fine_tuned_model_ckpt = torch.load(\n",
        "    args.downstream_model_checkpoint_fpath,\n",
        "    map_location = torch.device(\"cpu\")\n",
        ")\n",
        "\n",
        "pretrained_model_config = BertConfig.from_pretrained(\n",
        "    args.pretrained_model_name,\n",
        "    num_labels=fine_tuned_model_ckpt['state_dict']['model.classifier.bias'].shape.numel(),\n",
        "\n",
        ")\n",
        "#Bert 설정 로드\n",
        "\n",
        "from transformers import BertConfig, BertForSequenceClassification\n",
        "model = BertForSequenceClassification(pretrained_model_config)\n",
        "#Bert 모델 초기화\n",
        "\n",
        "model.load_state_dict({k.replace(\"model.\", \"\"): v for k, v in fine_tuned_model_ckpt['state_dict'].items()})\n",
        "#체크포인트 주입하기\n",
        "\n",
        "model.eval()\n",
        "#평가모드로 전환"
      ],
      "metadata": {
        "id": "mk6AQmc8tKCM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 인퍼런스 함수 선언"
      ],
      "metadata": {
        "id": "nyUhvXIbR1Kw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def inference_fn(sentence):\n",
        "    inputs = tokenizer(\n",
        "        [sentence],\n",
        "        max_length=args.max_seq_length,\n",
        "        padding=\"max_length\",\n",
        "        truncation=True,\n",
        "    )\n",
        "    with torch.no_grad():\n",
        "        outputs = model(**{k: torch.tensor(v) for k, v in inputs.items()})\n",
        "        prob = outputs.logits.softmax(dim=1)\n",
        "        positive_prob = round(prob[0][1].item(), 4)\n",
        "        negative_prob = round(prob[0][0].item(), 4)\n",
        "        pred = \"긍정 (positive)\" if torch.argmax(prob) == 1 else \"부정 (negative)\"\n",
        "    return {\n",
        "        'sentence': sentence,\n",
        "        'prediction': pred,\n",
        "        'positive_data': f\"긍정 {positive_prob}\",\n",
        "        'negative_data': f\"부정 {negative_prob}\",\n",
        "        'positive_width': f\"{positive_prob * 100}%\",\n",
        "        'negative_width': f\"{negative_prob * 100}%\",\n",
        "    }"
      ],
      "metadata": {
        "id": "70l0XG5xRzjM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 웹 서비스 시작하기"
      ],
      "metadata": {
        "id": "X4iTC5tFR90o"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from ratsnlp.nlpbook.classification import get_web_service_app\n",
        "app = get_web_service_app(inference_fn) # inference_fn : 플라스크라는 파이썬 라이브러리의 도움을 받아 웹 서비스 o\n",
        "app.run()"
      ],
      "metadata": {
        "id": "9nAK8N1FR_Xk"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}